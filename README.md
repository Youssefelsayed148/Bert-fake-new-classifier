# ğŸš€ Bert-Fake-News-Detector

A lightweight, encoder-only NLP project to **detect fake news headlines and articles**, trained using BERT on a balanced fake/real news dataset.  
This project demonstrates a typical workflow youâ€™d use in real-world machine learning engineering, including:

- ğŸ¤— Data loading and preprocessing with the Hugging Face Datasets library
- ğŸ”¥ Fine-tuning a pre-trained `bert-base-uncased` model for text classification
- ğŸ· Mapping output labels to human-friendly `REAL` and `FAKE` tags
- ğŸ“ˆ Evaluating with metrics like accuracy and F1
- â˜ï¸ Pushing the trained model to the Hugging Face Hub for easy sharing and reuse

---

## ğŸ— Model details
| Component  | Value |
|------------|-------|
| Architecture | BERT (bert-base-uncased) |
| Task | Binary text classification |
| Labels | `REAL` and `FAKE` |
| Training Data | Balanced dataset of real vs fake news articles |
| Training Framework | ğŸ¤— Transformers with PyTorch |
| Optimizations | fp16 training, early stopping, dynamic padding |

---

## ğŸš€ Usage
You can load and run inference directly with ğŸ¤— Transformers pipelines:
Read summary.py for an example

